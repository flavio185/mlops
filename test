# [START setup]
import datetime
import pandas as pd
import joblib

from google.cloud import storage


from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

from sklearn.externals import joblib



import ssl

# Determine CSV, label, and key columns
CSV_COLUMNS = ["etnia", 
               "sexo", 
               "casapropria",
               "outrasrendas", 
               "estadocivil", 
               "escolaridade",
               "renda",
               "idade"]
LABEL_COLUMN = "default"

ssl._create_default_https_context = ssl._create_unverified_context
url = 'https://raw.githubusercontent.com/flavio185/mlops/main/BaseDefault01.csv'
url2 = 'https://raw.githubusercontent.com/flavio185/mlops/main/BaseDefault02.csv'
dataset1 = pd.read_csv(url)
dataset2 = pd.read_csv(url2)
dataset=pd.concat([dataset1, dataset2])

# Remove the column we are trying to predict ('income-level') from our features list
# Convert the Dataframe to a lists of lists
train_features = dataset[CSV_COLUMNS].values.tolist()
# Create our training labels list, convert the Dataframe to a lists of lists
train_labels = (dataset[LABEL_COLUMN]).values.tolist()
# [END define-and-load-data]

# Create the classifier
classifier = RandomForestClassifier(random_state = 1,
                                  n_estimators = 750,
                                  max_depth = 15, 
                                  min_samples_split = 5,  min_samples_leaf = 1) 
                                  
model = classifier.fit(X_train, y_train)

y_predVC = model.predict(X_test)

accuracy = model.score(X_test, y_test)

print("Accuracy:", accuracy)

# Export the model to a file
model = 'model.joblib'
joblib.dump(model, 'model.joblib')

# Upload the model to GCS
bucket = storage.Client().bucket(BUCKET_NAME)
blob = bucket.blob('{}/{}'.format(
    datetime.datetime.now().strftime('census_%Y%m%d_%H%M%S'),
    model))
blob.upload_from_filename(model)
